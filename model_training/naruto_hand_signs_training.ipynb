{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naruto Hand Signs",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb5EVcB7lilL",
        "colab_type": "text"
      },
      "source": [
        "##Setup Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ZmbXxrknPz",
        "colab_type": "code",
        "outputId": "d74f080f-09b5-4f85-e4ab-ed5a1f839dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVdL_LJLzLR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W1P197IlGV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/htn19')\n",
        "# !unzip htn_train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkg1ejQtlhgG",
        "colab_type": "code",
        "outputId": "10edcd56-1fe9-41be-a2d4-621831e1a795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "input_size = 256\n",
        "class_names = [\"bird\", \"boar\", \"dog\", \"dragon\", \"hare\", \"horse\", \"monkey\", \"ox\", \"ram\", \"rat\", \"serpant\", \"tiger\", \"none\"]\n",
        "train_dir = \"/content/drive/My Drive/Colab Notebooks/htn19/train\"\n",
        "X_train = np.zeros((len(os.listdir(train_dir)), input_size, input_size, 3))\n",
        "Y_train = np.zeros((len(os.listdir(train_dir)), 13))\n",
        "image_files = os.listdir(train_dir)\n",
        "image_files.sort()\n",
        "count = 0\n",
        "\n",
        "prev_class = \"\"\n",
        "index = -1\n",
        "for num, file in enumerate(image_files):     \n",
        "    count += 1   \n",
        "    if file[0] != prev_class:\n",
        "        index += 1\n",
        "        if index > 12:\n",
        "            index = 12\n",
        "        label = np.zeros(13)\n",
        "        label[index] = 1\n",
        "        print(label, file)\n",
        "\n",
        "    Y_train[num] = label\n",
        "    image = cv2.imread(os.path.join(train_dir, file), 1)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)/255.\n",
        "    X_train[num] = image\n",
        "    prev_class = file[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] A1.jpg\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] B1.jpg\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] C1.jpg\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] D1.jpg\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] E1.jpg\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] F1.jpg\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] G1.jpg\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] H1.jpg\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] I1.jpg\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] J1.jpg\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] K1.jpg\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] L1.jpg\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] M1.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1f0epgIBx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "af49a9ea-b065-46a7-c984-5f7577290dac"
      },
      "source": [
        "test_dir = \"/content/drive/My Drive/Colab Notebooks/htn19/test\"\n",
        "X_test = np.zeros((len(os.listdir(test_dir)), input_size, input_size, 3))\n",
        "Y_test = np.zeros((len(os.listdir(test_dir)), 13))\n",
        "image_files = os.listdir(test_dir)\n",
        "image_files.sort()\n",
        "\n",
        "prev_class = \"\"\n",
        "index = -1\n",
        "for num, file in enumerate(image_files):        \n",
        "    if file[0] != prev_class:\n",
        "        index += 1\n",
        "        if index > 12:\n",
        "            index = 12\n",
        "        label = np.zeros(13)\n",
        "        label[index] = 1\n",
        "        print(label, file)\n",
        "\n",
        "    Y_test[num] = label\n",
        "    image = cv2.imread(os.path.join(test_dir, file), 1)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)/255.\n",
        "    X_test[num] = image\n",
        "    prev_class = file[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] A1.jpg\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] B1.jpg\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] C1.jpg\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] D1.jpg\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] E1.jpg\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] F1.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxPXeXz6_XRl",
        "colab_type": "code",
        "outputId": "456715f0-26c1-4e7c-97bd-9b02084e1cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "plt.imshow(X_train[0])\n",
        "print(Y_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7748, 256, 256, 3)\n",
            "(7748, 13)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhrDIKkxDJIawyCpMQySGsMgqflfhxiN46BfsaUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58I0oMtiIXc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "plt.imshow(X_test[0])\n",
        "print(Y_test[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEOZLOJXtpsL",
        "colab_type": "text"
      },
      "source": [
        "#Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT18VKGLlsc5",
        "colab_type": "text"
      },
      "source": [
        "##Model from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyISKkS0xL45",
        "colab_type": "text"
      },
      "source": [
        "###Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA4LLSD9cuSP",
        "colab_type": "code",
        "outputId": "0ebfd1e5-5365-474d-b2fd-8ca353ad631f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import keras.backend as K\n",
        "\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuCFNUaRmat8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; \n",
        "# !nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6YPQ-zbdNtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def HandSignModel(input_shape):\n",
        "    # Define the input placeholder as a tensor with shape input_shape. \n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv01')(X_input)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn01')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((2, 2), strides= (2, 2), name='max_pool1')(X)\n",
        "    \n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(128, (3, 3), strides = (2, 2), name = 'conv02')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn02')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((2, 2), strides= (2, 2), name='max_pool2')(X)\n",
        "    \n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(256, (3, 3), strides = (1, 1), name = 'conv03')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn03')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((2, 2), strides= (2, 2), name='max_pool3')(X)\n",
        "    \n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(512, (3, 3), strides = (1, 1), name = 'conv04')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn04')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((2, 2), strides= (2, 2), name='max_pool4')(X)\n",
        "    \n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(512, (3, 3), strides = (1, 1), name = 'conv05')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn05')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((2, 2), strides= (2, 2), name='max_pool5')(X)\n",
        "\n",
        "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(4096, activation='relu', name='fc01')(X)\n",
        "    X = Dense(13, activation='softmax', name='fc02')(X)\n",
        "\n",
        "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
        "    model = Model(inputs = X_input, outputs = X, name='HandSignModel')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8V9rOsWmlM9",
        "colab_type": "text"
      },
      "source": [
        "###Train and Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9jOYcAAfx-y",
        "colab_type": "code",
        "outputId": "f683b564-b22d-4443-c1a8-27c06bdfa69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "signModel = HandSignModel([input_size, input_size, 3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWAYrTATb5R2",
        "colab_type": "code",
        "outputId": "e9a3e020-4b65-4412-d2fb-cbaea469b31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "# Continue training from previous weights\n",
        "from keras.models import load_model\n",
        "\n",
        "signModel = load_model('/content/drive/My Drive/Colab Notebooks/htn19/custom_sign_model_v2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiMukO3DjM4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "signModel.compile(optimizer=Adam(lr=0.0001), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "datagen = image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    brightness_range=(0.7, 1.3),\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ")\n",
        "it = datagen.flow(X_train, Y_train)\n",
        "mc = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/htn19/custom_sign_model_v2.h5', verbose=1, monitor='loss',\n",
        "                     save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "# signModel.fit_generator(it, validation_data=(X_train, Y_train), steps_per_epoch=len(X_train) // 16,\n",
        "# \tepochs=2, shuffle=True, callbacks=[mc])\n",
        "signModel.fit(x=X_train, y=Y_train, epochs=10, batch_size=16, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXmWlpzDjTWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = signModel.evaluate(x=X_test, y=Y_test)\n",
        "\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZHdH7MBjhix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img_path = 'images/my_image.jpg'\n",
        "\n",
        "# img = image.load_img(img_path, target_size=(64, 64))\n",
        "# plt.imshow(img)\n",
        "\n",
        "# x = image.img_to_array(img)\n",
        "x = X_train[0]\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "plt.imshow(X_train[0])\n",
        "print(class_names[np.argmax(signModel.predict(x))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86QNzS6iBrpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signModel.save(\"/content/drive/My Drive/Colab Notebooks/htn19/custom_sign_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}